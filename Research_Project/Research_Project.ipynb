{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    from io import StringIO\n",
    "except ImportError:\n",
    "    from StringIO import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Scrape historical stock data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)\n",
    "\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def crawl_data(ticker, start_time, end_time):\n",
    "    env_url = 'https://finance.yahoo.com/quote/%s/history' % (ticker)\n",
    "    r = requests.get(env_url)\n",
    "    txt = r.content\n",
    "    cookie = r.cookies['B']\n",
    "    pattern = re.compile('.*\"CrumbStore\":\\{\"crumb\":\"(?P<crumb>[^\"]+)\"\\}')\n",
    "\n",
    "    for line in txt.splitlines():\n",
    "        m = pattern.match(line.decode(\"utf-8\"))\n",
    "        if m is not None:\n",
    "            crumb = m.groupdict()['crumb']\n",
    "\n",
    "    start = datetime.datetime.strptime(start_time, '%Y/%m/%d').strftime(\"%s\")\n",
    "    end = datetime.datetime.strptime(end_time, '%Y/%m/%d').strftime(\"%s\")\n",
    "\n",
    "    download_url = \"https://query1.finance.yahoo.com/v7/finance/download/%s?period1=%s&period2=%s&interval=1d&events=history&crumb=%s\" \\\n",
    "                    % (ticker, start, end, crumb)\n",
    "    data = requests.get(download_url, cookies={'B':cookie})\n",
    "\n",
    "    # 200 and 201 for success\n",
    "    if data.status_code != 200 and data.status_code != 201:\n",
    "        return None\n",
    "    print('{_ticker} successful!'.format(_ticker=ticker))\n",
    "    table = pd.read_csv(StringIO(data.content.decode('utf8')))\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_data(ticker_list, start_date, end_date):\n",
    "    new_ticker_list = []\n",
    "    for ticker in ticker_list:\n",
    "        for i in range(3):\n",
    "            table = crawl_data(ticker, start_date, end_date)\n",
    "            if table is None:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        table = pd.DataFrame(table[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']])\n",
    "        \n",
    "        # To ensure we have all 10 years' of data\n",
    "        if pd.to_datetime(table['Date'][0]) > datetime.datetime(2008,1,2):\n",
    "            continue\n",
    "        \n",
    "        table.to_csv('data/'+ticker+'.csv')\n",
    "        if len(table) > 0:\n",
    "            new_ticker_list.append(ticker)\n",
    "    return new_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ticker_list = get_tickers()#[0:10]\n",
    "ticker_list = ticker_list + [\"^GSPC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMM successful!\n",
      "ABT successful!\n",
      "ABBV successful!\n",
      "ABMD successful!\n",
      "ACN successful!\n",
      "ATVI successful!\n",
      "ADBE successful!\n",
      "AMD successful!\n",
      "AAP successful!\n",
      "AES successful!\n",
      "AET successful!\n",
      "AMG successful!\n",
      "AFL successful!\n",
      "A successful!\n",
      "APD successful!\n",
      "AKAM successful!\n",
      "ALK successful!\n",
      "ALB successful!\n",
      "ARE successful!\n",
      "ALXN successful!\n",
      "ALGN successful!\n",
      "ALLE successful!\n",
      "AGN successful!\n",
      "ADS successful!\n",
      "LNT successful!\n",
      "ALL successful!\n",
      "GOOGL successful!\n",
      "GOOG successful!\n",
      "MO successful!\n",
      "AMZN successful!\n",
      "AAL successful!\n",
      "AEP successful!\n",
      "AXP successful!\n",
      "AIG successful!\n",
      "AMT successful!\n",
      "AWK successful!\n",
      "ABC successful!\n",
      "AME successful!\n",
      "AMGN successful!\n",
      "APH successful!\n",
      "APC successful!\n",
      "ADI successful!\n",
      "ANDV successful!\n",
      "ANSS successful!\n",
      "ANTM successful!\n",
      "AON successful!\n",
      "AOS successful!\n",
      "APA successful!\n",
      "AIV successful!\n",
      "AAPL successful!\n",
      "AMAT successful!\n",
      "APTV successful!\n",
      "ADM successful!\n",
      "ARNC successful!\n",
      "AJG successful!\n",
      "AIZ successful!\n",
      "T successful!\n",
      "ADSK successful!\n",
      "ADP successful!\n",
      "AZO successful!\n",
      "AVB successful!\n",
      "AVY successful!\n",
      "BHGE successful!\n",
      "BLL successful!\n",
      "BAC successful!\n",
      "BK successful!\n",
      "BAX successful!\n",
      "BBT successful!\n",
      "BDX successful!\n",
      "BBY successful!\n",
      "BIIB successful!\n",
      "BLK successful!\n",
      "HRB successful!\n",
      "BA successful!\n",
      "BKNG successful!\n",
      "BWA successful!\n",
      "BXP successful!\n",
      "BSX successful!\n",
      "BHF successful!\n",
      "BMY successful!\n",
      "AVGO successful!\n",
      "BR successful!\n",
      "CHRW successful!\n",
      "CA successful!\n",
      "COG successful!\n",
      "CDNS successful!\n",
      "CPB successful!\n",
      "COF successful!\n",
      "CAH successful!\n",
      "KMX successful!\n",
      "CCL successful!\n",
      "CAT successful!\n",
      "CBOE successful!\n",
      "CBS successful!\n",
      "CELG successful!\n",
      "CNC successful!\n",
      "CNP successful!\n",
      "CTL successful!\n",
      "CERN successful!\n",
      "CF successful!\n",
      "SCHW successful!\n",
      "CHTR successful!\n",
      "CVX successful!\n",
      "CMG successful!\n",
      "CB successful!\n",
      "CHD successful!\n",
      "CI successful!\n",
      "XEC successful!\n",
      "CINF successful!\n",
      "CTAS successful!\n",
      "CSCO successful!\n",
      "C successful!\n",
      "CFG successful!\n",
      "CTXS successful!\n",
      "CLX successful!\n",
      "CME successful!\n",
      "CMS successful!\n",
      "KO successful!\n",
      "CTSH successful!\n",
      "CL successful!\n",
      "CMCSA successful!\n",
      "CMA successful!\n",
      "CAG successful!\n",
      "CXO successful!\n",
      "COP successful!\n",
      "ED successful!\n",
      "STZ successful!\n",
      "COO successful!\n",
      "GLW successful!\n",
      "COST successful!\n",
      "COTY successful!\n",
      "CCI successful!\n",
      "CSX successful!\n",
      "CMI successful!\n",
      "CVS successful!\n",
      "DHI successful!\n",
      "DHR successful!\n",
      "DRI successful!\n",
      "DVA successful!\n",
      "DE successful!\n",
      "DAL successful!\n",
      "XRAY successful!\n",
      "DVN successful!\n",
      "DLR successful!\n",
      "DFS successful!\n",
      "DISCA successful!\n",
      "DISCK successful!\n",
      "DISH successful!\n",
      "DG successful!\n",
      "DLTR successful!\n",
      "D successful!\n",
      "DOV successful!\n",
      "DWDP successful!\n",
      "DPS successful!\n",
      "DTE successful!\n",
      "DRE successful!\n",
      "DUK successful!\n",
      "DXC successful!\n",
      "ETFC successful!\n",
      "EMN successful!\n",
      "ETN successful!\n",
      "EBAY successful!\n",
      "ECL successful!\n",
      "EIX successful!\n",
      "EW successful!\n",
      "EA successful!\n",
      "EMR successful!\n",
      "ETR successful!\n",
      "EVHC successful!\n",
      "EOG successful!\n",
      "EQT successful!\n",
      "EFX successful!\n",
      "EQIX successful!\n",
      "EQR successful!\n",
      "ESS successful!\n",
      "EL successful!\n",
      "ES successful!\n",
      "RE successful!\n",
      "EXC successful!\n",
      "EXPE successful!\n",
      "EXPD successful!\n",
      "ESRX successful!\n",
      "EXR successful!\n",
      "XOM successful!\n",
      "FFIV successful!\n",
      "FB successful!\n",
      "FAST successful!\n",
      "FRT successful!\n",
      "FDX successful!\n",
      "FIS successful!\n",
      "FITB successful!\n",
      "FE successful!\n",
      "FISV successful!\n",
      "FLT successful!\n",
      "FLIR successful!\n",
      "FLS successful!\n",
      "FLR successful!\n",
      "FMC successful!\n",
      "FL successful!\n",
      "F successful!\n",
      "FTV successful!\n",
      "FBHS successful!\n",
      "BEN successful!\n",
      "FCX successful!\n",
      "GRMN successful!\n",
      "IT successful!\n",
      "GD successful!\n",
      "GE successful!\n",
      "GGP successful!\n",
      "GIS successful!\n",
      "GM successful!\n",
      "GPC successful!\n",
      "GILD successful!\n",
      "GPN successful!\n",
      "GS successful!\n",
      "GT successful!\n",
      "GWW successful!\n",
      "HAL successful!\n",
      "HBI successful!\n",
      "HOG successful!\n",
      "HRS successful!\n",
      "HIG successful!\n",
      "HAS successful!\n",
      "HCA successful!\n",
      "HCP successful!\n",
      "HP successful!\n",
      "HSIC successful!\n",
      "HSY successful!\n",
      "HES successful!\n",
      "HPE successful!\n",
      "HLT successful!\n",
      "HFC successful!\n",
      "HOLX successful!\n",
      "HD successful!\n",
      "HON successful!\n",
      "HRL successful!\n",
      "HST successful!\n",
      "HPQ successful!\n",
      "HUM successful!\n",
      "HBAN successful!\n",
      "HII successful!\n",
      "IDXX successful!\n",
      "INFO successful!\n",
      "ITW successful!\n",
      "ILMN successful!\n",
      "IR successful!\n",
      "INTC successful!\n",
      "ICE successful!\n",
      "IBM successful!\n",
      "INCY successful!\n",
      "IP successful!\n",
      "IPG successful!\n",
      "IFF successful!\n",
      "INTU successful!\n",
      "ISRG successful!\n",
      "IVZ successful!\n",
      "IPGP successful!\n",
      "IQV successful!\n",
      "IRM successful!\n",
      "JEC successful!\n",
      "JBHT successful!\n",
      "JEF successful!\n",
      "SJM successful!\n",
      "JNJ successful!\n",
      "JCI successful!\n",
      "JPM successful!\n",
      "JNPR successful!\n",
      "KSU successful!\n",
      "K successful!\n",
      "KEY successful!\n",
      "KMB successful!\n",
      "KIM successful!\n",
      "KMI successful!\n",
      "KLAC successful!\n",
      "KSS successful!\n",
      "KHC successful!\n",
      "KR successful!\n",
      "LB successful!\n",
      "LLL successful!\n",
      "LRCX successful!\n",
      "LEG successful!\n",
      "LEN successful!\n",
      "LLY successful!\n",
      "LNC successful!\n",
      "LKQ successful!\n",
      "LMT successful!\n",
      "L successful!\n",
      "LOW successful!\n",
      "LYB successful!\n",
      "MTB successful!\n",
      "MAC successful!\n",
      "M successful!\n",
      "MRO successful!\n",
      "MPC successful!\n",
      "MAR successful!\n",
      "MMC successful!\n",
      "MLM successful!\n",
      "MAS successful!\n",
      "MA successful!\n",
      "MKC successful!\n",
      "MCD successful!\n",
      "MCK successful!\n",
      "MDT successful!\n",
      "MRK successful!\n",
      "MET successful!\n",
      "MTD successful!\n",
      "MGM successful!\n",
      "KORS successful!\n",
      "MCHP successful!\n",
      "MU successful!\n",
      "MSFT successful!\n",
      "MAA successful!\n",
      "MHK successful!\n",
      "TAP successful!\n",
      "MDLZ successful!\n",
      "MNST successful!\n",
      "MCO successful!\n",
      "MS successful!\n",
      "MOS successful!\n",
      "MSI successful!\n",
      "MSCI successful!\n",
      "MYL successful!\n",
      "NDAQ successful!\n",
      "NOV successful!\n",
      "NKTR successful!\n",
      "NTAP successful!\n",
      "NFLX successful!\n",
      "NWL successful!\n",
      "NFX successful!\n",
      "NEM successful!\n",
      "NWSA successful!\n",
      "NWS successful!\n",
      "NEE successful!\n",
      "NLSN successful!\n",
      "NKE successful!\n",
      "NI successful!\n",
      "NBL successful!\n",
      "JWN successful!\n",
      "NSC successful!\n",
      "NTRS successful!\n",
      "NOC successful!\n",
      "NCLH successful!\n",
      "NRG successful!\n",
      "NUE successful!\n",
      "NVDA successful!\n",
      "ORLY successful!\n",
      "OXY successful!\n",
      "OMC successful!\n",
      "OKE successful!\n",
      "ORCL successful!\n",
      "PCAR successful!\n",
      "PKG successful!\n",
      "PH successful!\n",
      "PAYX successful!\n",
      "PYPL successful!\n",
      "PNR successful!\n",
      "PBCT successful!\n",
      "PEP successful!\n",
      "PKI successful!\n",
      "PRGO successful!\n",
      "PFE successful!\n",
      "PCG successful!\n",
      "PM successful!\n",
      "PSX successful!\n",
      "PNW successful!\n",
      "PXD successful!\n",
      "PNC successful!\n",
      "RL successful!\n",
      "PPG successful!\n",
      "PX successful!\n",
      "PFG successful!\n",
      "PG successful!\n",
      "PGR successful!\n",
      "PLD successful!\n",
      "PRU successful!\n",
      "PEG successful!\n",
      "PSA successful!\n",
      "PHM successful!\n",
      "PVH successful!\n",
      "QRVO successful!\n",
      "PWR successful!\n",
      "QCOM successful!\n",
      "RJF successful!\n",
      "RTN successful!\n",
      "O successful!\n",
      "RHT successful!\n",
      "REG successful!\n",
      "REGN successful!\n",
      "RF successful!\n",
      "RMD successful!\n",
      "RHI successful!\n",
      "ROK successful!\n",
      "COL successful!\n",
      "ROP successful!\n",
      "ROST successful!\n",
      "RCL successful!\n",
      "CRM successful!\n",
      "SBAC successful!\n",
      "SCG successful!\n",
      "SLB successful!\n",
      "STX successful!\n",
      "SEE successful!\n",
      "SRE successful!\n",
      "SHW successful!\n",
      "SPG successful!\n",
      "SWKS successful!\n",
      "SLG successful!\n",
      "SNA successful!\n",
      "SO successful!\n",
      "LUV successful!\n",
      "SPGI successful!\n",
      "SWK successful!\n",
      "SBUX successful!\n",
      "STT successful!\n",
      "SRCL successful!\n",
      "SYK successful!\n",
      "STI successful!\n",
      "SIVB successful!\n",
      "SYMC successful!\n",
      "SYF successful!\n",
      "SNPS successful!\n",
      "SYY successful!\n",
      "TROW successful!\n",
      "TTWO successful!\n",
      "TPR successful!\n",
      "TGT successful!\n",
      "TEL successful!\n",
      "FTI successful!\n",
      "TXN successful!\n",
      "TXT successful!\n",
      "TIF successful!\n",
      "TWTR successful!\n",
      "TJX successful!\n",
      "TMK successful!\n",
      "TSS successful!\n",
      "TSCO successful!\n",
      "TDG successful!\n",
      "TRV successful!\n",
      "TRIP successful!\n",
      "FOXA successful!\n",
      "FOX successful!\n",
      "TSN successful!\n",
      "ULTA successful!\n",
      "USB successful!\n",
      "UAA successful!\n",
      "UA successful!\n",
      "UNP successful!\n",
      "UAL successful!\n",
      "UNH successful!\n",
      "UPS successful!\n",
      "URI successful!\n",
      "UTX successful!\n",
      "UHS successful!\n",
      "UNM successful!\n",
      "VFC successful!\n",
      "VLO successful!\n",
      "VAR successful!\n",
      "VTR successful!\n",
      "VRSN successful!\n",
      "VRSK successful!\n",
      "VZ successful!\n",
      "VRTX successful!\n",
      "VIAB successful!\n",
      "V successful!\n",
      "VNO successful!\n",
      "VMC successful!\n",
      "WMT successful!\n",
      "WBA successful!\n",
      "DIS successful!\n",
      "WM successful!\n",
      "WAT successful!\n",
      "WEC successful!\n",
      "WFC successful!\n",
      "WELL successful!\n",
      "WDC successful!\n",
      "WU successful!\n",
      "WRK successful!\n",
      "WY successful!\n",
      "WHR successful!\n",
      "WMB successful!\n",
      "WLTW successful!\n",
      "WYNN successful!\n",
      "XEL successful!\n",
      "XLNX successful!\n",
      "XL successful!\n",
      "XYL successful!\n",
      "YUM successful!\n",
      "ZBH successful!\n",
      "ZION successful!\n",
      "ZTS successful!\n",
      "^GSPC successful!\n"
     ]
    }
   ],
   "source": [
    "start_date = '2008/01/01'\n",
    "end_date = '2017/12/31'\n",
    "ticker_list = save_data(ticker_list, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Stock data processing\n",
    "\n",
    "Read data from local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_list = []\n",
    "for filename in os.listdir('/Users/luyang/Desktop/Invesco/data'):\n",
    "    ticker = filename.split('.')[0]\n",
    "    if len(ticker) > 0:\n",
    "        ticker_list.append(ticker)\n",
    "len(ticker_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculate returns and combine all the returns into a single data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BKNG\n",
      "WELL\n",
      "BHF\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "ticker_list_cur = ticker_list\n",
    "for ticker in ticker_list_cur:\n",
    "    data = pd.read_csv('data/' + ticker + '.csv', index_col=1)\n",
    "    try:\n",
    "        ret = pd.DataFrame(np.log(data['Adj Close'] / data['Adj Close'].shift()))\n",
    "        ret.columns = [ticker]\n",
    "        ret.index = data.index.values\n",
    "        data_list.append(ret)\n",
    "    except:\n",
    "        print(ticker)\n",
    "        ticker_list_cur.remove(ticker)\n",
    "returns = reduce(lambda left, right: pd.merge(left, right, how = 'outer', left_index=True, right_index=True), data_list)\n",
    "\n",
    "returns = returns.drop(returns.index[0])\n",
    "returns = returns.dropna(1)\n",
    "returns.index = pd.to_datetime(returns.index)\n",
    "ticker_list_cur = returns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# volume_list = []\n",
    "# ticker_list_cur = ticker_list\n",
    "# for ticker in ticker_list_cur:\n",
    "#     data = pd.read_csv('data/' + ticker + '.csv', index_col=1)\n",
    "#     try:\n",
    "#         vol = pd.DataFrame(data['Volume'])\n",
    "#         vol.columns = [ticker]\n",
    "#         vol.index = data.index.values\n",
    "#         volume_list.append(vol)\n",
    "#     except:\n",
    "#         print(ticker)\n",
    "#         ticker_list_cur.remove(ticker)\n",
    "        \n",
    "# volume = reduce(lambda left, right: \n",
    "#                 pd.merge(left, right, how = 'outer', left_index=True, right_index=True), volume_list)\n",
    "# volume = volume.drop(volume.index[0])\n",
    "# volume = volume.dropna(1)\n",
    "# ticker_list_cur = returns.columns\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(volume)\n",
    "# volume = scaler.transform(volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Factor data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Read the historical factor data saved in local drive.\n",
    "\n",
    "Both versions of factors include Fama-Fench 5 factors (Market excess return, risk free return, SMB, HML, RMW, CMA), short-term reversal, long-term reversal, and momentum. \n",
    "\n",
    "Version 1 (factor_12) contains industry factors of 12 industries only, while version 2 (factor_49) contains 49 industry factors and public sentiment factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>RF</th>\n",
       "      <th>LT_Rev</th>\n",
       "      <th>Mom</th>\n",
       "      <th>ST_Rev</th>\n",
       "      <th>NoDur</th>\n",
       "      <th>...</th>\n",
       "      <th>Manuf</th>\n",
       "      <th>Enrgy</th>\n",
       "      <th>Chems</th>\n",
       "      <th>BusEq</th>\n",
       "      <th>Telcm</th>\n",
       "      <th>Utils</th>\n",
       "      <th>Shops</th>\n",
       "      <th>Hlth</th>\n",
       "      <th>Money</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>-2.59</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.97</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>-4.15</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>-2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.98</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>-1.69</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-3.21</td>\n",
       "      <td>-1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-09</th>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>1.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mkt-RF   SMB   HML   RMW   CMA    RF  LT_Rev  Mom     ST_Rev  \\\n",
       "2008-01-03   -0.03 -0.76 -0.40 -0.05 -0.44  0.01   -0.43    1.60   -0.98   \n",
       "2008-01-04   -2.59 -0.43  0.28 -0.01  0.34  0.01    0.46    0.57   -0.42   \n",
       "2008-01-07    0.02 -0.09  0.22  0.19  1.20  0.01    0.96   -0.52    0.05   \n",
       "2008-01-08   -1.69 -0.33 -0.96  0.20 -0.07  0.01    0.06    1.01   -1.43   \n",
       "2008-01-09    0.94 -0.73 -0.45  0.46  0.25  0.01   -0.08    0.25   -0.08   \n",
       "\n",
       "            NoDur  ...    Manuf  Enrgy  Chems  BusEq  Telcm  Utils  Shops  \\\n",
       "2008-01-03   0.60  ...     0.41   0.34   0.27  -0.22  -0.09   0.20  -1.78   \n",
       "2008-01-04  -1.10  ...    -2.97  -2.43  -1.52  -4.15  -1.96  -0.24  -2.52   \n",
       "2008-01-07   1.98  ...    -1.39  -1.04   0.12  -0.88   0.65   1.78   1.05   \n",
       "2008-01-08  -0.13  ...    -2.43  -1.52  -1.04  -2.63  -2.65  -0.13  -1.94   \n",
       "2008-01-09   1.03  ...     0.44   1.40   0.45   1.73  -0.15   1.29   0.78   \n",
       "\n",
       "            Hlth   Money  Other  \n",
       "2008-01-03   0.32  -0.45  -0.25  \n",
       "2008-01-04  -1.17  -2.70  -2.92  \n",
       "2008-01-07   1.82   0.59  -0.47  \n",
       "2008-01-08   0.93  -3.21  -1.98  \n",
       "2008-01-09   1.61   1.32   0.68  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 1: 12 industry, no sentiment\n",
    "factor_list = ['F-F_5_Factors', 'F-F_LT_Reversal_Factor_daily', \n",
    "               'F-F_Momentum_Factor_daily', 'F-F_ST_Reversal_Factor_daily',\n",
    "               'Industry_12']\n",
    "\n",
    "data_list = []\n",
    "for factor in factor_list:\n",
    "    data = pd.read_csv('factor/' + factor + '.csv', index_col=0)\n",
    "    data.index = pd.to_datetime(data.index, format='%Y%m%d')\n",
    "    data_list.append(data[(data.index>=datetime.datetime(2008,1,1)) & (data.index<=datetime.datetime(2017,12,31))])\n",
    "    \n",
    "factor_12 = reduce(lambda left,right: pd.merge(left,right,left_index=True,right_index=True), data_list)\n",
    "factor_12 = factor_12.drop(factor_12.index[0])\n",
    "factor_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# version 2: 49 industry, with sentiment\n",
    "factor_list = ['F-F_5_Factors', 'F-F_LT_Reversal_Factor_daily', \n",
    "               'F-F_Momentum_Factor_daily', 'F-F_ST_Reversal_Factor_daily',\n",
    "               'Industry_49']\n",
    "\n",
    "data_list = []\n",
    "for factor in factor_list:\n",
    "    data = pd.read_csv('factor/' + factor + '.csv', index_col=0)\n",
    "    data.index = pd.to_datetime(data.index, format='%Y%m%d')\n",
    "    data_list.append(data[(data.index>=datetime.datetime(2008,1,1)) & (data.index<=datetime.datetime(2017,12,31))])\n",
    "factor_49 = reduce(lambda left,right: pd.merge(left,right,left_index=True,right_index=True), data_list)\n",
    "\n",
    "data = pd.read_csv('factor/AAII-AAII_SENTIMENT.csv', index_col=0)\n",
    "data.index = pd.to_datetime(data.index, format='%m/%d/%y')\n",
    "data = data[(data.index>=datetime.datetime(2008,1,1)) & (data.index<=datetime.datetime(2017,12,31))]\n",
    "factor_49 = pd.merge(factor_49, data, how = 'outer',left_index=True,right_index=True)\n",
    "\n",
    "factor_49[['Bullish','Neutral','Bearish']] = factor_49[['Bullish','Neutral','Bearish']].fillna(method = 'ffill')\n",
    "factor_49 = factor_49.drop(factor_49.index[[0,1]])\n",
    "factor_49.dropna()\n",
    "returns = returns[returns.index.isin(factor_49.index)]\n",
    "factor_49 = factor_49[factor_49.index.isin(returns.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# tscv = TimeSeriesSplit(n_splits=2)\n",
    "# for train_index, test_index in tscv.split(factor):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional feature & Modeling implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_lagged_returns(ticker, train_X, train_y, test_X, test_y):\n",
    "    train_X_cur = train_X.copy()\n",
    "    train_X_cur['lag'] = train_y[ticker].shift()\n",
    "    test_X_cur = test_X.copy()\n",
    "    test_X_cur['lag'] = test_y[ticker].shift()\n",
    "    return train_X_cur.iloc[1:], train_y[ticker].iloc[1:], test_X_cur.iloc[1:], test_y[ticker].iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_volume(ticker, train_X, test_X):\n",
    "    train_X_cur = train_X.copy()\n",
    "    train_X_cur = pd.merge(train_X_cur, pd.DataFrame(vol), how = 'inner', \n",
    "                           left_index = True, right_index = True)\n",
    "    test_X_cur = test_X.copy()\n",
    "    test_X_cur = pd.merge(test_X_cur, pd.DataFrame(vol), how = 'inner', \n",
    "                          left_index = True, right_index = True)\n",
    "    return train_X_cur, test_X_cur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linear_regression(train_X, train_y, test_X, test_y):\n",
    "    \n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(train_X, train_y)\n",
    "    lin_reg.predict(test_X)\n",
    "    \n",
    "    return [lin_reg.score(train_X, train_y), lin_reg.score(test_X, test_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def kernel_ridge(train_X, train_y, test_X, test_y, alpha, kernel):\n",
    "    k_ridge = KernelRidge(alpha=alpha, kernel=kernel, degree=2, coef0=1)\n",
    "    k_ridge.fit(train_X, train_y)\n",
    "    k_ridge.predict(test_X)\n",
    "    \n",
    "    return [k_ridge.score(train_X, train_y), k_ridge.score(test_X, test_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest regression\n",
    "\n",
    "Can provide us with information related to feature importance, so we can know which features can explain the returns the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def rf_regressor(train_X, train_y, test_X, test_y, n):\n",
    "    rfr = RandomForestRegressor(n_estimators = n, max_features = 'sqrt')\n",
    "    rfr.fit(train_X, train_y)\n",
    "    rfr.predict(test_X)\n",
    "    \n",
    "    return [[rfr.score(train_X, train_y), rfr.score(test_X, test_y)],\n",
    "            rfr.feature_importances_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "def train_test_split(returns,factor,split_ratio):\n",
    "    train_y = returns.iloc[0:int(len(returns) * split_ratio)]\n",
    "    test_y = returns.iloc[int(len(returns) * split_ratio):]\n",
    "    train_X = factor.iloc[0:int(len(returns) * split_ratio)]\n",
    "    test_X = factor.iloc[int(len(returns) * split_ratio):]\n",
    "    return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression, 12 industry factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>446.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.567950</td>\n",
       "      <td>0.330598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.133713</td>\n",
       "      <td>0.244071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.175267</td>\n",
       "      <td>-0.790004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.469069</td>\n",
       "      <td>0.206517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.576807</td>\n",
       "      <td>0.306683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.671102</td>\n",
       "      <td>0.472642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.997742</td>\n",
       "      <td>0.995157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train        test\n",
       "count  446.000000  446.000000\n",
       "mean     0.567950    0.330598\n",
       "std      0.133713    0.244071\n",
       "min      0.175267   -0.790004\n",
       "25%      0.469069    0.206517\n",
       "50%      0.576807    0.306683\n",
       "75%      0.671102    0.472642\n",
       "max      0.997742    0.995157"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = train_test_split(returns,factor_12,0.8)\n",
    "rsquared = {}\n",
    "for ticker in ticker_list_cur:\n",
    "    rsquared[ticker] = linear_regression(train_X, train_y[ticker], test_X, test_y[ticker])\n",
    "pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel ridge regression, 12 industry factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 1\n",
      "2018-06-23 11:00:53.696522\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.635753    0.293341\n",
      "std      0.122884    0.259149\n",
      "min      0.224539   -1.303237\n",
      "25%      0.549525    0.169131\n",
      "50%      0.647641    0.282797\n",
      "75%      0.730984    0.448000\n",
      "max      0.998796    0.994280\n",
      "alpha = 5\n",
      "2018-06-23 11:03:09.592714\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.613500    0.329285\n",
      "std      0.126575    0.238689\n",
      "min      0.206318   -0.678773\n",
      "25%      0.519543    0.210302\n",
      "50%      0.625793    0.304941\n",
      "75%      0.710379    0.474461\n",
      "max      0.998631    0.994021\n",
      "alpha = 10\n",
      "2018-06-23 11:05:21.123292\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.603335    0.336836\n",
      "std      0.127869    0.232724\n",
      "min      0.199204   -0.613916\n",
      "25%      0.510031    0.216668\n",
      "50%      0.616180    0.312081\n",
      "75%      0.701874    0.476863\n",
      "max      0.998460    0.993367\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = train_test_split(returns,factor_12,0.8)\n",
    "kernel = 'poly'\n",
    "for alpha in [1,5,10]:\n",
    "    rsquared = {}\n",
    "    print('alpha = ' + str(alpha))\n",
    "    print(datetime.datetime.now())\n",
    "    for ticker in ticker_list_cur:\n",
    "        rsquared[ticker] = kernel_ridge(train_X, train_y[ticker], test_X, test_y[ticker], alpha, kernel)\n",
    "    print(pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel ridge regression, 49 industry factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 1\n",
      "2018-06-23 15:35:17.047578\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.802071    0.317135\n",
      "std      0.089073    0.263115\n",
      "min      0.500453   -1.322124\n",
      "25%      0.746287    0.164006\n",
      "50%      0.816031    0.310747\n",
      "75%      0.871594    0.487351\n",
      "max      0.999372    0.991326\n",
      "alpha = 5\n",
      "2018-06-23 15:37:34.314037\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.741909    0.375095\n",
      "std      0.107389    0.229225\n",
      "min      0.400441   -0.594557\n",
      "25%      0.671355    0.230463\n",
      "50%      0.760016    0.365790\n",
      "75%      0.824539    0.537164\n",
      "max      0.998934    0.989905\n",
      "alpha = 10\n",
      "2018-06-23 15:39:52.066300\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.714899    0.382100\n",
      "std      0.113039    0.221576\n",
      "min      0.356668   -0.461789\n",
      "25%      0.642475    0.239722\n",
      "50%      0.731962    0.377556\n",
      "75%      0.801016    0.541088\n",
      "max      0.998502    0.988072\n",
      "alpha = 20\n",
      "2018-06-23 15:42:14.948573\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.686176    0.378119\n",
      "std      0.117003    0.214909\n",
      "min      0.318842   -0.499829\n",
      "25%      0.605513    0.242639\n",
      "50%      0.702279    0.380259\n",
      "75%      0.774507    0.528958\n",
      "max      0.997664    0.984763\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = train_test_split(returns,factor_49,0.8)\n",
    "kernel = 'poly'\n",
    "for alpha in [1,5,10,20]:\n",
    "    rsquared = {}\n",
    "    print('alpha = ' + str(alpha))\n",
    "    print(datetime.datetime.now())\n",
    "    for ticker in ticker_list_cur:\n",
    "        rsquared[ticker] = kernel_ridge(train_X, train_y[ticker], test_X, test_y[ticker], alpha, kernel)\n",
    "    print(pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With lagged return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression, 12 industry factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>446.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.569963</td>\n",
       "      <td>0.330161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.133940</td>\n",
       "      <td>0.241448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.176550</td>\n",
       "      <td>-0.788999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.472049</td>\n",
       "      <td>0.205782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.579847</td>\n",
       "      <td>0.306414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.672043</td>\n",
       "      <td>0.474027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.997766</td>\n",
       "      <td>0.995217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train        test\n",
       "count  446.000000  446.000000\n",
       "mean     0.569963    0.330161\n",
       "std      0.133940    0.241448\n",
       "min      0.176550   -0.788999\n",
       "25%      0.472049    0.205782\n",
       "50%      0.579847    0.306414\n",
       "75%      0.672043    0.474027\n",
       "max      0.997766    0.995217"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = train_test_split(returns,factor_12,0.8)\n",
    "rsquared = {}\n",
    "for ticker in ticker_list_cur:\n",
    "    train_X_cur, train_y_cur, test_X_cur, test_y_cur = add_lagged_returns(ticker, train_X, train_y, test_X, test_y)\n",
    "    rsquared[ticker] = linear_regression(train_X_cur, train_y_cur, test_X_cur, test_y_cur)\n",
    "    \n",
    "pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>446.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.573472</td>\n",
       "      <td>0.326275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.131524</td>\n",
       "      <td>0.244194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.177544</td>\n",
       "      <td>-0.789711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.196766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.582108</td>\n",
       "      <td>0.301577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.672667</td>\n",
       "      <td>0.481310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.997843</td>\n",
       "      <td>0.995187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train        test\n",
       "count  446.000000  446.000000\n",
       "mean     0.573472    0.326275\n",
       "std      0.131524    0.244194\n",
       "min      0.177544   -0.789711\n",
       "25%      0.475904    0.196766\n",
       "50%      0.582108    0.301577\n",
       "75%      0.672667    0.481310\n",
       "max      0.997843    0.995187"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_X, train_y, test_X, test_y = train_test_split(returns,factor_12,0.8)\n",
    "# rsquared = {}\n",
    "# for ticker in ticker_list_cur:\n",
    "#     train_X_cur, train_y_cur, test_X_cur, test_y_cur = add_lagged_returns(ticker, train_X, train_y, test_X, test_y)\n",
    "#     train_X_cur, test_X_cur = add_volume(ticker, train_X_cur, test_X_cur)\n",
    "#     rsquared[ticker] = linear_regression(train_X_cur, train_y_cur, test_X_cur, test_y_cur)\n",
    "\n",
    "# pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel ridge regression, 12 industry factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 1\n",
      "2018-06-23 14:04:34.264018\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.635269    0.296292\n",
      "std      0.123051    0.256271\n",
      "min      0.223977   -1.221721\n",
      "25%      0.549360    0.174283\n",
      "50%      0.646864    0.282477\n",
      "75%      0.731524    0.448752\n",
      "max      0.998791    0.994276\n",
      "alpha = 5\n",
      "2018-06-23 14:06:40.674458\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.612570    0.330028\n",
      "std      0.126745    0.237885\n",
      "min      0.205570   -0.646931\n",
      "25%      0.518474    0.210527\n",
      "50%      0.624626    0.306389\n",
      "75%      0.709937    0.474824\n",
      "max      0.998621    0.993986\n",
      "alpha = 10\n",
      "2018-06-23 14:08:46.099290\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.602336    0.337014\n",
      "std      0.128018    0.232181\n",
      "min      0.198451   -0.611187\n",
      "25%      0.508844    0.216103\n",
      "50%      0.615084    0.311053\n",
      "75%      0.701495    0.477108\n",
      "max      0.998440    0.993289\n",
      "kernel = rbf\n",
      "2018-06-23 14:10:50.923900\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.391989    0.329451\n",
      "std      0.075527    0.164036\n",
      "min      0.170534   -0.058526\n",
      "25%      0.338526    0.213822\n",
      "50%      0.395338    0.299260\n",
      "75%      0.446780    0.439608\n",
      "max      0.643983    0.940839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "train_X, train_y, test_X, test_y = train_test_split(returns,factor_12,0.8)\n",
    "\n",
    "kernel = 'poly'\n",
    "for alpha in [1,5,10]:\n",
    "    rsquared = {}\n",
    "    print('alpha = ' + str(alpha))\n",
    "    print(datetime.datetime.now())\n",
    "    for ticker in ticker_list_cur:\n",
    "        train_X_cur, train_y_cur, test_X_cur, test_y_cur = add_lagged_returns(ticker, train_X, train_y, test_X, test_y)\n",
    "#         train_X_cur, test_X_cur = add_volume(ticker, train_X_cur, test_X_cur)\n",
    "#         train_X_cur = normalize(train_X_cur)\n",
    "#         test_X_cur = normalize(test_X_cur)\n",
    "        rsquared[ticker] = kernel_ridge(train_X_cur, train_y_cur, test_X_cur, test_y_cur, alpha, kernel)\n",
    "    print(pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe())\n",
    "    \n",
    "kernel = 'rbf'\n",
    "rsquared = {}\n",
    "print('kernel = ' + str(kernel))\n",
    "print(datetime.datetime.now())\n",
    "for ticker in ticker_list_cur:\n",
    "    train_X_cur, train_y_cur, test_X_cur, test_y_cur = add_lagged_returns(ticker, train_X, train_y, test_X, test_y)\n",
    "    train_X_cur, test_X_cur = add_volume(ticker, train_X_cur, test_X_cur)\n",
    "    rsquared[ticker] = kernel_ridge(train_X, train_y[ticker], test_X, test_y[ticker], alpha, kernel)\n",
    "print(pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel ridge regression, 49 industry factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 1\n",
      "2018-06-23 14:19:37.019940\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.800922    0.318512\n",
      "std      0.089502    0.261748\n",
      "min      0.498691   -1.303086\n",
      "25%      0.744980    0.168865\n",
      "50%      0.814976    0.311134\n",
      "75%      0.870991    0.490568\n",
      "max      0.999366    0.991298\n",
      "alpha = 5\n",
      "2018-06-23 14:21:59.489338\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.740712    0.375264\n",
      "std      0.107724    0.228880\n",
      "min      0.398198   -0.585845\n",
      "25%      0.669605    0.230249\n",
      "50%      0.758692    0.364022\n",
      "75%      0.823678    0.536517\n",
      "max      0.998922    0.989851\n",
      "alpha = 10\n",
      "2018-06-23 14:24:27.785519\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.713686    0.381885\n",
      "std      0.113318    0.221415\n",
      "min      0.354621   -0.462517\n",
      "25%      0.640755    0.239714\n",
      "50%      0.730641    0.378239\n",
      "75%      0.800101    0.541125\n",
      "max      0.998484    0.987988\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = train_test_split(returns,factor_49,0.8)\n",
    "kernel = 'poly'\n",
    "for alpha in [1,5,10]:\n",
    "    rsquared = {}\n",
    "    print('alpha = ' + str(alpha))\n",
    "    print(datetime.datetime.now())\n",
    "    for ticker in ticker_list_cur:\n",
    "        train_X_cur, train_y_cur, test_X_cur, test_y_cur = add_lagged_returns(ticker, train_X, train_y, test_X, test_y)\n",
    "\n",
    "        train_y_cur = train_y_cur[train_y_cur.index.isin(train_X_cur.index)]\n",
    "        test_y_cur = test_y_cur[test_y_cur.index.isin(test_X_cur.index)]\n",
    "        rsquared[ticker] = kernel_ridge(train_X_cur, train_y_cur, \n",
    "                                        test_X_cur, test_y_cur, alpha, kernel)\n",
    "    print(pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel ridge regression with rbf kernel, 49 industry factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 10\n",
      "2018-06-23 14:27:53.020860\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.342091    0.283530\n",
      "std      0.054724    0.125364\n",
      "min      0.194416   -0.018701\n",
      "25%      0.303372    0.187738\n",
      "50%      0.340758    0.268493\n",
      "75%      0.381295    0.368364\n",
      "max      0.569612    0.768757\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = train_test_split(returns,factor_49,0.8)\n",
    "kernel = 'rbf'\n",
    "\n",
    "rsquared = {}\n",
    "print('alpha = ' + str(alpha))\n",
    "print(datetime.datetime.now())\n",
    "for ticker in ticker_list_cur:\n",
    "    train_X_cur, train_y_cur, test_X_cur, test_y_cur = add_lagged_returns(ticker, train_X, train_y, test_X, test_y)\n",
    "#       train_X_cur, test_X_cur = add_volume(ticker, train_X_cur, test_X_cur)\n",
    "    train_y_cur = train_y_cur[train_y_cur.index.isin(train_X_cur.index)]\n",
    "    test_y_cur = test_y_cur[test_y_cur.index.isin(test_X_cur.index)]\n",
    "    rsquared[ticker] = kernel_ridge(train_X_cur, train_y_cur, \n",
    "                                    test_X_cur, test_y_cur, alpha, kernel)\n",
    "print(pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest with 49 industry factor, control max_features for the purpose of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 100\n",
      "2018-06-23 15:22:32.384853\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.935966    0.373600\n",
      "std      0.018227    0.186442\n",
      "min      0.883760   -0.148818\n",
      "25%      0.923227    0.246016\n",
      "50%      0.938831    0.366209\n",
      "75%      0.949617    0.503974\n",
      "max      0.996545    0.974885\n",
      "2018-06-23 15:31:32.932491\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = train_test_split(returns,factor_49,0.8)\n",
    "\n",
    "n_estimators = [100]\n",
    "for n in n_estimators:\n",
    "    print('n_estimators = ' + str(n))\n",
    "    print(datetime.datetime.now())\n",
    "    rsquared = {}\n",
    "    feature_importance = {}\n",
    "    for ticker in ticker_list_cur:\n",
    "        train_X_cur, train_y_cur, test_X_cur, test_y_cur = add_lagged_returns(ticker, train_X, train_y, test_X, test_y)\n",
    "        train_y_cur = train_y_cur[train_y_cur.index.isin(train_X_cur.index)]\n",
    "        test_y_cur = test_y_cur[test_y_cur.index.isin(test_X_cur.index)]\n",
    "        result = rf_regressor(train_X_cur, train_y_cur, test_X_cur, test_y_cur, n)\n",
    "        rsquared[ticker] = result[0]\n",
    "        feature_importance[ticker] = result[1]\n",
    "    print(pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe())\n",
    "    \n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest parameter tuning (n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 50\n",
      "2018-06-23 16:09:41.440913\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.932784    0.364296\n",
      "std      0.019304    0.189125\n",
      "min      0.862542   -0.387404\n",
      "25%      0.918915    0.227681\n",
      "50%      0.935474    0.355004\n",
      "75%      0.947418    0.493885\n",
      "max      0.996127    0.972774\n",
      "n_estimators = 100\n",
      "2018-06-23 16:14:12.565493\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.935855    0.373508\n",
      "std      0.018367    0.187219\n",
      "min      0.882531   -0.148344\n",
      "25%      0.922359    0.240936\n",
      "50%      0.938809    0.362633\n",
      "75%      0.949919    0.503843\n",
      "max      0.996677    0.976096\n",
      "n_estimators = 200\n",
      "2018-06-23 16:23:14.778219\n",
      "            train        test\n",
      "count  446.000000  446.000000\n",
      "mean     0.937355    0.378467\n",
      "std      0.017763    0.186842\n",
      "min      0.883523   -0.139370\n",
      "25%      0.924767    0.247781\n",
      "50%      0.940186    0.369259\n",
      "75%      0.950550    0.509790\n",
      "max      0.996817    0.976705\n",
      "2018-06-23 16:41:36.636967\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = train_test_split(returns,factor_49,0.8)\n",
    "\n",
    "n_estimators = [50,100,200]\n",
    "for n in n_estimators:\n",
    "    print('n_estimators = ' + str(n))\n",
    "    print(datetime.datetime.now())\n",
    "    rsquared = {}\n",
    "    feature_importance = {}\n",
    "    for ticker in ticker_list_cur:\n",
    "        train_X_cur, train_y_cur, test_X_cur, test_y_cur = add_lagged_returns(ticker, train_X, train_y, test_X, test_y)\n",
    "        train_y_cur = train_y_cur[train_y_cur.index.isin(train_X_cur.index)]\n",
    "        test_y_cur = test_y_cur[test_y_cur.index.isin(test_X_cur.index)]\n",
    "        result = rf_regressor(train_X_cur, train_y_cur, test_X_cur, test_y_cur, n)\n",
    "        rsquared[ticker] = result[0]\n",
    "#         feature_importance[ticker] = result[1]\n",
    "    print(pd.DataFrame(rsquared,index = ['train', 'test']).transpose().describe())\n",
    "    \n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.006074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bearish</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.013686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bullish</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.028427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.006245</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.015712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.008035</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.040222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.008155</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.009736</td>\n",
       "      <td>0.022360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT_Rev</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.021780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agric</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.007568</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>0.086641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gold</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.008454</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.398195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST_Rev</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.008383</td>\n",
       "      <td>0.010219</td>\n",
       "      <td>0.027730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ships</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.085228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PerSv</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>0.011201</td>\n",
       "      <td>0.075422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>0.061483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mom</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.008053</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>0.051972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.009750</td>\n",
       "      <td>0.007636</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.063533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.006136</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.201082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FabPr</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.010732</td>\n",
       "      <td>0.101638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guns</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.015767</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>0.272802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soda</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.009332</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.011120</td>\n",
       "      <td>0.123620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.010565</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.009828</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>0.049189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coal</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.010863</td>\n",
       "      <td>0.011918</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.078598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toys</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.014177</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>0.011766</td>\n",
       "      <td>0.218783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hlth</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>0.192558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fun</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>0.009536</td>\n",
       "      <td>0.013678</td>\n",
       "      <td>0.184046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mines</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.012935</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>0.186959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardw</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.009122</td>\n",
       "      <td>0.012262</td>\n",
       "      <td>0.149686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beer</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>0.016146</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.008633</td>\n",
       "      <td>0.012236</td>\n",
       "      <td>0.195748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Txtls</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>0.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boxes</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.015540</td>\n",
       "      <td>0.152669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.013776</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.009319</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.016206</td>\n",
       "      <td>0.154958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drugs</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.016017</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.015499</td>\n",
       "      <td>0.147167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steel</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.016049</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>0.016515</td>\n",
       "      <td>0.157575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedEq</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.010225</td>\n",
       "      <td>0.015840</td>\n",
       "      <td>0.167008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aero</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.017941</td>\n",
       "      <td>0.190960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clths</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>0.020981</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.017033</td>\n",
       "      <td>0.186679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meals</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.017128</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>0.013642</td>\n",
       "      <td>0.019127</td>\n",
       "      <td>0.189494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.017151</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.177729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnstr</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.015664</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0.014820</td>\n",
       "      <td>0.020706</td>\n",
       "      <td>0.153466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oil</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.018689</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>0.204677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chips</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.019701</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.137655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rubbr</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>0.010048</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.013704</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.025658</td>\n",
       "      <td>0.112108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chems</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.020552</td>\n",
       "      <td>0.018285</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.014301</td>\n",
       "      <td>0.021968</td>\n",
       "      <td>0.126875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trans</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.012558</td>\n",
       "      <td>0.016593</td>\n",
       "      <td>0.022784</td>\n",
       "      <td>0.152787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autos</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.021136</td>\n",
       "      <td>0.013897</td>\n",
       "      <td>0.005668</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.018556</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.159438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Softw</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.021177</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.014520</td>\n",
       "      <td>0.023713</td>\n",
       "      <td>0.144114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Util</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.039902</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.007020</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.213805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rtail</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.021958</td>\n",
       "      <td>0.022010</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.010595</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.143555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telcm</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.021992</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.013696</td>\n",
       "      <td>0.018436</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.147894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banks</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.023128</td>\n",
       "      <td>0.030055</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>0.018228</td>\n",
       "      <td>0.168034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElcEq</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.023519</td>\n",
       "      <td>0.017555</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.018720</td>\n",
       "      <td>0.027263</td>\n",
       "      <td>0.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RlEst</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.023975</td>\n",
       "      <td>0.021873</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.010696</td>\n",
       "      <td>0.016833</td>\n",
       "      <td>0.027932</td>\n",
       "      <td>0.123048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabEq</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.024052</td>\n",
       "      <td>0.018262</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>0.031017</td>\n",
       "      <td>0.148026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paper</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.025290</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.016308</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>0.030187</td>\n",
       "      <td>0.159258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insur</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.023165</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>0.016675</td>\n",
       "      <td>0.029436</td>\n",
       "      <td>0.135860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fin</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.025854</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.011420</td>\n",
       "      <td>0.015884</td>\n",
       "      <td>0.026161</td>\n",
       "      <td>0.146277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mach</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.026138</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.011054</td>\n",
       "      <td>0.017269</td>\n",
       "      <td>0.032702</td>\n",
       "      <td>0.135528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BldMt</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.015643</td>\n",
       "      <td>0.023040</td>\n",
       "      <td>0.033235</td>\n",
       "      <td>0.122029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whlsl</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.029957</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.020297</td>\n",
       "      <td>0.027263</td>\n",
       "      <td>0.037170</td>\n",
       "      <td>0.117074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BusSv</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.025343</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>0.044431</td>\n",
       "      <td>0.107933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mkt-RF</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.042883</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>0.041411</td>\n",
       "      <td>0.052847</td>\n",
       "      <td>0.114853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         count      mean       std       min       25%       50%       75%  \\\n",
       "RF       446.0  0.000914  0.000688  0.000083  0.000513  0.000711  0.001065   \n",
       "Bearish  446.0  0.005720  0.002076  0.000343  0.004116  0.005537  0.006795   \n",
       "Bullish  446.0  0.006319  0.002484  0.000429  0.004742  0.005898  0.007508   \n",
       "Neutral  446.0  0.006679  0.002258  0.000359  0.005127  0.006245  0.007732   \n",
       "CMA      446.0  0.008035  0.003518  0.000616  0.005661  0.007444  0.009300   \n",
       "SMB      446.0  0.008155  0.002947  0.001056  0.006010  0.007652  0.009736   \n",
       "LT_Rev   446.0  0.008256  0.002899  0.000583  0.006430  0.007752  0.009606   \n",
       "Agric    446.0  0.008260  0.005639  0.000729  0.005921  0.007568  0.009629   \n",
       "Gold     446.0  0.008454  0.018723  0.000649  0.005738  0.007163  0.008989   \n",
       "ST_Rev   446.0  0.008786  0.003026  0.000830  0.006832  0.008383  0.010219   \n",
       "Ships    446.0  0.009260  0.005577  0.001340  0.006400  0.008238  0.010482   \n",
       "PerSv    446.0  0.009497  0.005297  0.001304  0.006356  0.008548  0.011201   \n",
       "RMW      446.0  0.009604  0.007121  0.000508  0.006361  0.007934  0.009737   \n",
       "Mom      446.0  0.009621  0.006246  0.000568  0.006375  0.008053  0.010617   \n",
       "HML      446.0  0.009750  0.007636  0.000397  0.006061  0.007838  0.010283   \n",
       "Smoke    446.0  0.009835  0.010330  0.001056  0.006136  0.007900  0.010945   \n",
       "FabPr    446.0  0.009885  0.007261  0.000541  0.006283  0.008020  0.010732   \n",
       "Guns     446.0  0.010050  0.015767  0.000839  0.006305  0.008095  0.010304   \n",
       "Soda     446.0  0.010097  0.009332  0.001373  0.006323  0.008244  0.011120   \n",
       "lag      446.0  0.010565  0.004490  0.000550  0.007410  0.009828  0.012569   \n",
       "Coal     446.0  0.010863  0.011918  0.001082  0.005974  0.007719  0.010061   \n",
       "Toys     446.0  0.010870  0.014177  0.000634  0.006608  0.008691  0.011766   \n",
       "Hlth     446.0  0.011681  0.015564  0.000789  0.005837  0.007499  0.010884   \n",
       "Fun      446.0  0.011796  0.012400  0.001909  0.006995  0.009536  0.013678   \n",
       "Mines    446.0  0.012935  0.015697  0.001493  0.006502  0.008229  0.011205   \n",
       "Hardw    446.0  0.013006  0.014282  0.003194  0.006954  0.009122  0.012262   \n",
       "Beer     446.0  0.013054  0.016146  0.003156  0.006538  0.008633  0.012236   \n",
       "Txtls    446.0  0.013183  0.013397  0.000773  0.007105  0.009669  0.014726   \n",
       "Boxes    446.0  0.013564  0.010581  0.003858  0.009141  0.011696  0.015540   \n",
       "Books    446.0  0.013776  0.010008  0.003110  0.009319  0.012246  0.016206   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "Drugs    446.0  0.016017  0.021038  0.003228  0.006302  0.008621  0.015499   \n",
       "Steel    446.0  0.016049  0.015068  0.004369  0.008984  0.011309  0.016515   \n",
       "MedEq    446.0  0.016509  0.019694  0.003500  0.007103  0.010225  0.015840   \n",
       "Aero     446.0  0.016884  0.016380  0.003889  0.010745  0.013450  0.017941   \n",
       "Clths    446.0  0.016920  0.020981  0.001571  0.007981  0.010968  0.017033   \n",
       "Meals    446.0  0.017128  0.016016  0.003714  0.009440  0.013642  0.019127   \n",
       "Other    446.0  0.017151  0.011203  0.005727  0.011074  0.014498  0.019934   \n",
       "Cnstr    446.0  0.018401  0.015664  0.004418  0.010830  0.014820  0.020706   \n",
       "Oil      446.0  0.018689  0.031239  0.003860  0.006740  0.009502  0.012747   \n",
       "Chips    446.0  0.019701  0.019824  0.003975  0.010320  0.013879  0.020033   \n",
       "Rubbr    446.0  0.020456  0.010048  0.003662  0.013704  0.019050  0.025658   \n",
       "Chems    446.0  0.020552  0.018285  0.004148  0.010623  0.014301  0.021968   \n",
       "Trans    446.0  0.020719  0.018134  0.003743  0.012558  0.016593  0.022784   \n",
       "Autos    446.0  0.021136  0.013897  0.005668  0.012246  0.018556  0.026667   \n",
       "Softw    446.0  0.021177  0.019250  0.003937  0.010711  0.014520  0.023713   \n",
       "Util     446.0  0.021505  0.039902  0.003235  0.007020  0.010030  0.015304   \n",
       "Rtail    446.0  0.021958  0.022010  0.004134  0.010595  0.015526  0.022500   \n",
       "Telcm    446.0  0.021992  0.016005  0.005833  0.013696  0.018436  0.024224   \n",
       "Banks    446.0  0.023128  0.030055  0.003898  0.007971  0.010145  0.018228   \n",
       "ElcEq    446.0  0.023519  0.017555  0.004871  0.012892  0.018720  0.027263   \n",
       "RlEst    446.0  0.023975  0.021873  0.003956  0.010696  0.016833  0.027932   \n",
       "LabEq    446.0  0.024052  0.018262  0.004880  0.012252  0.019279  0.031017   \n",
       "Paper    446.0  0.025290  0.014183  0.005675  0.016308  0.021688  0.030187   \n",
       "Insur    446.0  0.025826  0.023165  0.004710  0.012029  0.016675  0.029436   \n",
       "Fin      446.0  0.025854  0.024704  0.004925  0.011420  0.015884  0.026161   \n",
       "Mach     446.0  0.026138  0.021150  0.005480  0.011054  0.017269  0.032702   \n",
       "BldMt    446.0  0.026443  0.016246  0.004859  0.015643  0.023040  0.033235   \n",
       "Whlsl    446.0  0.029957  0.015094  0.004101  0.020297  0.027263  0.037170   \n",
       "BusSv    446.0  0.036362  0.016244  0.008242  0.025343  0.033669  0.044431   \n",
       "Mkt-RF   446.0  0.042883  0.015206  0.009383  0.032005  0.041411  0.052847   \n",
       "\n",
       "              max  \n",
       "RF       0.006074  \n",
       "Bearish  0.013686  \n",
       "Bullish  0.028427  \n",
       "Neutral  0.015712  \n",
       "CMA      0.040222  \n",
       "SMB      0.022360  \n",
       "LT_Rev   0.021780  \n",
       "Agric    0.086641  \n",
       "Gold     0.398195  \n",
       "ST_Rev   0.027730  \n",
       "Ships    0.085228  \n",
       "PerSv    0.075422  \n",
       "RMW      0.061483  \n",
       "Mom      0.051972  \n",
       "HML      0.063533  \n",
       "Smoke    0.201082  \n",
       "FabPr    0.101638  \n",
       "Guns     0.272802  \n",
       "Soda     0.123620  \n",
       "lag      0.049189  \n",
       "Coal     0.078598  \n",
       "Toys     0.218783  \n",
       "Hlth     0.192558  \n",
       "Fun      0.184046  \n",
       "Mines    0.186959  \n",
       "Hardw    0.149686  \n",
       "Beer     0.195748  \n",
       "Txtls    0.181200  \n",
       "Boxes    0.152669  \n",
       "Books    0.154958  \n",
       "...           ...  \n",
       "Drugs    0.147167  \n",
       "Steel    0.157575  \n",
       "MedEq    0.167008  \n",
       "Aero     0.190960  \n",
       "Clths    0.186679  \n",
       "Meals    0.189494  \n",
       "Other    0.177729  \n",
       "Cnstr    0.153466  \n",
       "Oil      0.204677  \n",
       "Chips    0.137655  \n",
       "Rubbr    0.112108  \n",
       "Chems    0.126875  \n",
       "Trans    0.152787  \n",
       "Autos    0.159438  \n",
       "Softw    0.144114  \n",
       "Util     0.213805  \n",
       "Rtail    0.143555  \n",
       "Telcm    0.147894  \n",
       "Banks    0.168034  \n",
       "ElcEq    0.162278  \n",
       "RlEst    0.123048  \n",
       "LabEq    0.148026  \n",
       "Paper    0.159258  \n",
       "Insur    0.135860  \n",
       "Fin      0.146277  \n",
       "Mach     0.135528  \n",
       "BldMt    0.122029  \n",
       "Whlsl    0.117074  \n",
       "BusSv    0.107933  \n",
       "Mkt-RF   0.114853  \n",
       "\n",
       "[62 rows x 8 columns]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(feature_importance).transpose()\n",
    "importance.columns = list(factor_49.columns.values)+['lag']\n",
    "importance.describe().transpose().sort_values('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project summary & Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is a general research on the factors explaining stock return. I have included all the S&P500 stocks here except the ones without complete data in the period 2008/1/1 to 2017/12/31.\n",
    "\n",
    "I started from linear regression and using only the factors as explaining variable. The performance was not very good with high level of overfitting. Therefore, I tried kernel ridge regression with more features (more industry categories and sentiment factor), as ridge regression can relieve the problem of overfitting while the kernel can capture non-linear relationship between the factors and the stock returns. \n",
    "\n",
    "However, these two models cannot give us any information on feature importance, which we would like to have in order to understand how the features can explain the returns. Therefore, I further tested random forest with different number of estimators. We can see that although still suffering from overfitting, random forest regression can give us the highest training and testing R-squared among all the models. The average R-squared in training set is as high as 93.5%, that means the factors we have found can indeed explain the returns to a very large extent, however, the parameters are not persistent, which result in the poor performance in the testing set. \n",
    "\n",
    "According to the feature importance, the most important feature is market excess return, while others including individual industry performance. The traditionally recognized factors like SMB, HML and MOM are not very important here. This may due to the fact that we are trying to use general market factor to explain individual stock performance. Therefore, if we can calculate stock-specific factors, they may have more explaining power. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "1. Include stock return moving average instead of lagged return as a factor.\n",
    "2. Generate more stock-specific factors.\n",
    "3. Try other models and regularization methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
